{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "63423"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:03,252 - config - INFO - Loading environment variables from: /home/olande/Desktop/Rag_Techniques/.env\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add the current directory to the path\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Import the hierarchical RAG components\n",
    "from document_processor import HierarchicalDocumentProcessor, get_document_stats\n",
    "from embedding import EmbeddingGenerator\n",
    "from vector_store import HierarchicalVectorStore\n",
    "from retrieval import HierarchicalRetrievalPipeline\n",
    "from llm_interface import LLMInterface\n",
    "from config import (\n",
    "    validate_config,\n",
    "    TOP_K_ROOT,\n",
    "    TOP_K_LEAF,\n",
    "    KB_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "91584"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:04,243 - config - INFO - All required configuration variables are present.\n",
      "2025-05-22 23:42:04,670 - document_processor - INFO - Initialized HierarchicalDocumentProcessor with knowledge base path: /home/olande/Desktop/Rag_Techniques/HRAG/books\n",
      "2025-05-22 23:42:04,672 - document_processor - INFO - Leaf chunk size: 1000, Root chunk size: 4000\n",
      "2025-05-22 23:42:04,701 - embedding - INFO - Initialized EmbeddingGenerator with model: models/text-embedding-004\n",
      "2025-05-22 23:42:04,702 - embedding - INFO - Embedding dimensions: 768\n",
      "2025-05-22 23:42:06,534 - vector_store - INFO - Pinecone index already exists: hrag-gemini-768\n",
      "2025-05-22 23:42:08,016 - embedding - INFO - Initialized EmbeddingGenerator with model: models/text-embedding-004\n",
      "2025-05-22 23:42:08,018 - embedding - INFO - Embedding dimensions: 768\n",
      "2025-05-22 23:42:08,437 - vector_store - INFO - Pinecone index already exists: hrag-gemini-768\n",
      "2025-05-22 23:42:08,760 - retrieval - INFO - Initialized HierarchicalRetriever with top_k_root=3, top_k_leaf=5\n",
      "2025-05-22 23:42:08,763 - retrieval - INFO - Initialized HierarchicalRetrievalPipeline with top_k_root=3, top_k_leaf=5\n",
      "2025-05-22 23:42:08,837 - llm_interface - INFO - Initialized LLMInterface with model: meta-llama/llama-3.1-8b-instruct\n",
      "2025-05-22 23:42:08,840 - __main__ - INFO - Initialized HierarchicalRAG with top_k_root=3, top_k_leaf=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical RAG system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the HierarchicalRAG\n",
    "class HierarchicalRAG:\n",
    "    \"\"\"Main class for the Hierarchical RAG system.\"\"\"\n",
    "    \n",
    "    def __init__(self, top_k_root: int = TOP_K_ROOT, top_k_leaf: int = TOP_K_LEAF):\n",
    "        \"\"\"\n",
    "        Initialize the Hierarchical RAG system.\n",
    "\n",
    "        \"\"\"\n",
    "        # Validate configuration\n",
    "        if not validate_config():\n",
    "            raise ValueError(\"Invalid configuration\")\n",
    "        \n",
    "        self.document_processor = HierarchicalDocumentProcessor()\n",
    "        self.embedding_generator = EmbeddingGenerator()\n",
    "        self.vector_store = HierarchicalVectorStore()\n",
    "        self.retrieval_pipeline = HierarchicalRetrievalPipeline(\n",
    "            top_k_root=top_k_root,\n",
    "            top_k_leaf=top_k_leaf\n",
    "        )\n",
    "        self.llm_interface = LLMInterface()\n",
    "        \n",
    "        logger.info(f\"Initialized HierarchicalRAG with top_k_root={top_k_root}, top_k_leaf={top_k_leaf}\")\n",
    "    \n",
    "    def index_documents(self, force_reindex: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process and index documents for hierarchical retrieval.\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Check if documents are already indexed\n",
    "        stats = self.vector_store.get_index_stats()\n",
    "        root_count = stats.get(\"namespaces\", {}).get(\"root\", {}).get(\"vector_count\", 0)\n",
    "        leaf_count = stats.get(\"namespaces\", {}).get(\"leaf\", {}).get(\"vector_count\", 0)\n",
    "        \n",
    "        if root_count > 0 and leaf_count > 0 and not force_reindex:\n",
    "            logger.info(f\"Documents already indexed: {root_count} root chunks, {leaf_count} leaf chunks\")\n",
    "            logger.info(\"Use force_reindex=True to reindex documents\")\n",
    "            return {\n",
    "                \"status\": \"already_indexed\",\n",
    "                \"root_count\": root_count,\n",
    "                \"leaf_count\": leaf_count\n",
    "            }\n",
    "        \n",
    "        # If forcing reindex, delete existing vectors\n",
    "        if force_reindex and (root_count > 0 or leaf_count > 0):\n",
    "            logger.info(\"Forcing reindex, deleting existing vectors...\")\n",
    "            self.vector_store.delete_all()\n",
    "        \n",
    "        # Process documents into hierarchical chunks\n",
    "        logger.info(\"Processing documents into hierarchical chunks...\")\n",
    "        root_chunks, leaf_chunks = self.document_processor.process_documents()\n",
    "        \n",
    "        # Generate embeddings for root chunks\n",
    "        logger.info(\"Generating embeddings for root chunks...\")\n",
    "        root_chunks_with_embeddings = self.embedding_generator.generate_embeddings_for_chunks(\n",
    "            root_chunks, \"root\"\n",
    "        )\n",
    "        \n",
    "        # Generate embeddings for leaf chunks\n",
    "        logger.info(\"Generating embeddings for leaf chunks...\")\n",
    "        leaf_chunks_with_embeddings = self.embedding_generator.generate_embeddings_for_chunks(\n",
    "            leaf_chunks, \"leaf\"\n",
    "        )\n",
    "        \n",
    "        # Index root chunks\n",
    "        logger.info(\"Indexing root chunks...\")\n",
    "        root_upsert_count = self.vector_store.upsert_root_chunks(root_chunks_with_embeddings)\n",
    "        \n",
    "        # Index leaf chunks\n",
    "        logger.info(\"Indexing leaf chunks...\")\n",
    "        leaf_upsert_count = self.vector_store.upsert_leaf_chunks(leaf_chunks_with_embeddings)\n",
    "        \n",
    "        # Calculate indexing time\n",
    "        indexing_time = time.time() - start_time\n",
    "        \n",
    "        # Return indexing statistics\n",
    "        indexing_stats = {\n",
    "            \"status\": \"indexed\",\n",
    "            \"root_count\": root_upsert_count,\n",
    "            \"leaf_count\": leaf_upsert_count,\n",
    "            \"indexing_time\": indexing_time\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Indexing completed in {indexing_time:.2f} seconds\")\n",
    "        logger.info(f\"Indexed {root_upsert_count} root chunks and {leaf_upsert_count} leaf chunks\")\n",
    "        \n",
    "        return indexing_stats\n",
    "    \n",
    "    def query(self, query_text: str, root_filter: Optional[Dict[str, Any]] = None, leaf_filter: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a query through the hierarchical RAG pipeline.\n",
    "\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Retrieve relevant chunks using hierarchical retrieval\n",
    "        logger.info(f\"Retrieving relevant chunks for query: {query_text}\")\n",
    "        retrieval_result = self.retrieval_pipeline.run(\n",
    "            query=query_text,\n",
    "            root_filter=root_filter,\n",
    "            leaf_filter=leaf_filter\n",
    "        )\n",
    "        \n",
    "        # Generate response using the LLM\n",
    "        logger.info(\"Generating response...\")\n",
    "        llm_response = self.llm_interface.generate_hierarchical_rag_response(\n",
    "            query=query_text,\n",
    "            context=retrieval_result[\"context\"]\n",
    "        )\n",
    "        \n",
    "        # Calculate query time\n",
    "        query_time = time.time() - start_time\n",
    "        \n",
    "        # Combine results\n",
    "        result = {\n",
    "            \"query\": query_text,\n",
    "            \"answer\": llm_response[\"text\"],\n",
    "            \"context\": retrieval_result[\"context\"],\n",
    "            \"root_chunks\": retrieval_result[\"root_chunks\"],\n",
    "            \"leaf_chunks\": retrieval_result[\"leaf_chunks\"],\n",
    "            \"query_time\": query_time\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Query processed in {query_time:.2f} seconds\")\n",
    "        return result\n",
    "\n",
    "# Initialize the system\n",
    "rag = HierarchicalRAG(top_k_root=3, top_k_leaf=5)\n",
    "print(\"Hierarchical RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "62a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Base Statistics:\n",
      "Path: /home/olande/Desktop/Rag_Techniques/HRAG/books\n",
      "Total Files: 3\n",
      "Total Size: 0.28 MB\n",
      "File Types: {'.txt': 3}\n"
     ]
    }
   ],
   "source": [
    "# Print document statistics\n",
    "doc_stats = get_document_stats()\n",
    "print(f\"Knowledge Base Statistics:\")\n",
    "print(f\"Path: {KB_PATH}\")\n",
    "print(f\"Total Files: {doc_stats['total_files']}\")\n",
    "print(f\"Total Size: {doc_stats['total_size_mb']} MB\")\n",
    "print(f\"File Types: {doc_stats['file_types']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "90a52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:10,812 - __main__ - INFO - Documents already indexed: 40 root chunks, 106 leaf chunks\n",
      "2025-05-22 23:42:10,815 - __main__ - INFO - Use force_reindex=True to reindex documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Status: already_indexed\n",
      "Root Chunks: 40\n",
      "Leaf Chunks: 106\n"
     ]
    }
   ],
   "source": [
    "# Index documents\n",
    "# Set force_reindex=True to reindex documents that are already indexed\n",
    "index_stats = rag.index_documents(force_reindex=False)\n",
    "print(f\"Indexing Status: {index_stats['status']}\")\n",
    "print(f\"Root Chunks: {index_stats['root_count']}\")\n",
    "print(f\"Leaf Chunks: {index_stats['leaf_count']}\")\n",
    "if 'indexing_time' in index_stats:\n",
    "    print(f\"Indexing Time: {index_stats['indexing_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "fdc1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:10,840 - __main__ - INFO - Retrieving relevant chunks for query: Who studies statistics and programming in Kenyatta University?\n",
      "2025-05-22 23:42:10,842 - retrieval - INFO - Retrieving chunks for query: Who studies statistics and programming in Kenyatta University?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who studies statistics and programming in Kenyatta University?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:13,988 - vector_store - INFO - Root query returned 3 results\n",
      "2025-05-22 23:42:14,219 - vector_store - INFO - Leaf query returned 6 results\n",
      "2025-05-22 23:42:14,223 - retrieval - INFO - Retrieved 3 root chunks and 6 leaf chunks\n",
      "2025-05-22 23:42:14,226 - __main__ - INFO - Generating response...\n",
      "2025-05-22 23:42:14,232 - llm_interface - INFO - Generating response for prompt: \n",
      "            Question: Who studies statistics and ...\n",
      "2025-05-22 23:42:18,191 - llm_interface - INFO - Generated response: **Who Studies Statistics and Programming in Kenyat...\n",
      "2025-05-22 23:42:18,193 - __main__ - INFO - Query processed in 7.35 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "**Who Studies Statistics and Programming in Kenyatta University?**\n",
      "\n",
      "Based on the hierarchical context provided, the answer is as follows:\n",
      "\n",
      "* **Chris Olande** is a student of Statistics and Programming at Kenyatta University. This information can be found in **Section 1**, where it is stated that \"Chris Olande is a statistics and programming student at Kenyatta University with a strong background in data science, machine learning, and artificial intelligence.\"\n",
      "* **Chris Olande's academic background** in statistics is complemented by a robust understanding of programming, especially in Python. His technical repertoire includes proficiency in libraries such as NumPy, pandas, PyTorch, and Hugging Face Transformers. This information can be found in **Section 1**, **Passage 2**, where it is stated that \"At Kenyatta University, he has distinguished himself through rigorous coursework and hands-on projects. His technical repertoire includes proficiency in libraries such as NumPy, pandas, matplotlib, seaborn, scikit-learn, PyTorch, and Hugging Face Transformers.\"\n",
      "* **Chris Olande's academic pursuits** reflect not only a mastery of foundational principles in data science and programming but also a passion for innovative applications in real-world contexts, including education and artificial intelligence. This information can be found in **Section 1**, where it is stated that \"His academic and practical pursuits reflect not only a mastery of foundational principles in data science and programming, but also a passion for innovative applications in real-world contexts, including education and artificial intelligence.\"\n",
      "\n",
      "In conclusion, based on the hierarchical context provided, it is clear that **Chris Olande** studies statistics and programming at Kenyatta University.\n",
      "\n",
      "Query Time: 7.35 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ask questions...\n",
    "def ask_question(query):\n",
    "    print(f\"Query: {query}\")\n",
    "    result = rag.query(query)\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(result[\"answer\"])\n",
    "    print(f\"\\nQuery Time: {result['query_time']:.2f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Query about my biographie\n",
    "query = \"Who studies statistics and programming in Kenyatta University?\"\n",
    "result = ask_question(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "b02c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context:\n",
      "\n",
      "\n",
      "[Section 1] (Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/olande.txt)\n",
      "\n",
      "Summary: Here is a concise summary of Chris Olande's professional profile:\n",
      "\n",
      "Chris Olande is a statistics and programming student at Kenyatta University with a strong background in data science, machine learning, and artificial intelligence. He has a proven track record of applying statistical rigor and cutting-edge machine learning techniques to real-world problems, particularly in education and AI. His expertise includes proficiency in Python, NumPy, pandas, PyTorch, and Hugging Face Transformers. He has worked on projects such as sentiment analysis, natural language processing, and retrieval-augmented generation systems. Chris is a leader in education and community engagement, and is committed to nurturing curiosity and STEM literacy among younger learners. He is a methodical, results-oriented, and collaborative individual with a strong work ethic and a passion for lifelong learning.\n",
      "Passage 1: This dual commitment—to technology and to people—makes Chris a well-rounded and impactful contributor in any professional setting.\n",
      "\n",
      "Professional Traits and Work Ethic\n",
      "\n",
      "Chris is methodical, results-oriented, and deeply inquisitive. He approaches problems analytically, balancing statistical rigor with creative thinking. His code is clean, well-documented, and adheres to best practices in software development. Whether working independently or as part of a team, he brings discipline, reliability, and a collaborative spirit.\n",
      "\n",
      "He is also a continuous learner. His willingness to experiment with new frameworks, keep up with industry trends, and learn from feedback positions him for long-term success in the fast-evolving tech landscape.\n",
      "\n",
      "Career Aspirations and Potential\n",
      "\n",
      "Given his trajectory, Chris is well-positioned for roles in data science, machine learning engineering, research, or AI systems development. His current focus on agentic RAGs suggests a future in intelligent information systems and AI product development, especially those requiring real-time reasoning and adaptive behavior.\n",
      "\n",
      "He could thrive in environments such as research labs, AI startups, ed-tech companies, or advanced analytics units in large organizations. With his blend of statistical depth, programming expertise, and interpersonal insight, Chris is not only a problem solver but a builder of intelligent systems that matter.\n",
      "\n",
      "In Conclusion\n",
      "\n",
      "Chris Olande is a promising young professional whose blend of technical competence, educational leadership, and forward-thinking innovation makes him stand out. As he continues his journey in statistics and programming at Kenyatta University, he is steadily building a foundation for meaningful, high-impact contributions to both industry and society.\n",
      "\n",
      "He exemplifies what it means to be a 21st-century technologist: skilled, thoughtful, and driven by a clear sense of purpose.\n",
      "Passage 2: Chris Olande: A Professional Profile\n",
      "\n",
      "Chris Olande is a dynamic and intellectually curious student of Statistics and Programming at Kenyatta University, with a growing portfolio of sophisticated projects that blend statistical rigor with cutting-edge machine learning techniques. His academic and practical pursuits reflect not only a mastery of foundational principles in data science and programming, but also a passion for innovative applications in real-world contexts, including education and artificial intelligence.\n",
      "\n",
      "From his meticulous handling of sentiment classification tasks using state-of-the-art transformer models to his leadership in organizing educational field studies, Chris demonstrates a rare combination of technical excellence, strategic thinking, and human-centered values. His ability to bridge theory and practice places him at the forefront of a new generation of data-driven professionals.\n",
      "\n",
      "Academic Background and Technical Expertise\n",
      "\n",
      "Chris's academic foundation in statistics is complemented by a robust understanding of programming, especially in Python. At Kenyatta University, he has distinguished himself through rigorous coursework and hands-on projects. His technical repertoire includes proficiency in libraries such as NumPy, pandas, matplotlib, seaborn, scikit-learn, PyTorch, and Hugging Face Transformers. This allows him to work fluidly across the full data science pipeline—from data wrangling and exploratory analysis to model building, evaluation, and deployment.\n",
      "\n",
      "He has undertaken projects that demonstrate applied knowledge of exploratory factor analysis (EFA), hypothesis testing, regression modeling, and time series analysis. In programming, he has shown fluency in building modular systems, implementing neural networks, and developing natural language processing (NLP) pipelines.\n",
      "\n",
      "Machine Learning and NLP Projects\n",
      "\n",
      "One of Chris's standout projects involves training and fine-tuning transformer models, such as BERT and DistilBERT, on the Rotten Tomatoes movie review dataset. His work here is exemplary, combining modern NLP practices with hands-on experimentation using both Hugging Face Trainer and custom training loops. He has incorporated best practices such as early stopping, performance tracking with Weights & Biases, and parameter tuning for robust sentiment classification.\n",
      "\n",
      "Further pushing the envelope, Chris has explored retrieval-augmented generation (RAG) systems, implementing a modular ConversationalRAG class that integrates OpenAI and Hugging Face models, LangChain, and vector stores for document-based question answering. His design balances clarity and extensibility, reflecting solid architectural thinking.\n",
      "\n",
      "Agentic RAG and Knowledge Systems\n",
      "\n",
      "Chris is currently advancing his work in the domain of agentic RAG systems—an area at the frontier of AI research and application. His vision is to create ultra-modern knowledge agents capable of autonomous planning, reasoning, memory management, and external tool use. To realize this, he leverages LangChain Expression Language (LCEL), OpenRouter models, and well-structured API integrations.\n",
      "\n",
      "He has emphasized modular codebases, separating components into distinct files and classes to promote reuse, clarity, and scalability. Chris’s agentic systems also show sensitivity to the evolving landscape of tools, prioritizing developer-friendly abstractions without sacrificing control or customization.\n",
      "\n",
      "Leadership in Education and Community Engagement\n",
      "\n",
      "In addition to his technical pursuits, Chris has demonstrated leadership in education by organizing a field study for Grade 7 students to visit Impala Glass Industries in Nairobi. This initiative reflects his commitment to nurturing curiosity and STEM literacy among younger learners. His work in this domain underscores a broader commitment to education as a vehicle for empowerment and societal progress.\n",
      "\n",
      "[Section 2] (Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt)\n",
      "\n",
      "Summary: Here is a concise summary:\n",
      "\n",
      "Project Gutenberg is a digital library of free eBooks, founded by Professor Michael S. Hart, that can be accessed at www.gutenberg.org. Donations are accepted to support the project, which can be made through various methods, including online payments and credit card donations.\n",
      "Passage 1: Please check the Project Gutenberg web pages for current donation\n",
      "methods and addresses. Donations are accepted in a number of other\n",
      "ways including checks, online payments and credit card donations. To\n",
      "donate, please visit: www.gutenberg.org/donate.\n",
      "\n",
      "Section 5. General Information About Project Gutenberg™ electronic works\n",
      "\n",
      "Professor Michael S. Hart was the originator of the Project\n",
      "Gutenberg™ concept of a library of electronic works that could be\n",
      "freely shared with anyone. For forty years, he produced and\n",
      "distributed Project Gutenberg™ eBooks with only a loose network of\n",
      "volunteer support.\n",
      "\n",
      "Project Gutenberg™ eBooks are often created from several printed\n",
      "editions, all of which are confirmed as not protected by copyright in\n",
      "the U.S. unless a copyright notice is included. Thus, we do not\n",
      "necessarily keep eBooks in compliance with any particular paper\n",
      "edition.\n",
      "\n",
      "Most people start at our website which has the main PG search\n",
      "facility: www.gutenberg.org.\n",
      "\n",
      "This website includes information about Project Gutenberg™,\n",
      "including how to make donations to the Project Gutenberg Literary\n",
      "Archive Foundation, how to help produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n",
      "\n",
      "[Section 3] (Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt)\n",
      "\n",
      "Summary: Here is a concise summary of the text:\n",
      "\n",
      "**Terms of Use for Project Gutenberg Electronic Works**\n",
      "\n",
      "* Permission is required to charge a fee or distribute works on different terms than specified.\n",
      "* Project Gutenberg disclaims all liability for damages, costs, and expenses, except for a limited right of replacement or refund within 90 days.\n",
      "* Works are provided \"as-is\" with no warranties of any kind, including merchantability or fitness for purpose.\n",
      "* Users agree to indemnify and hold harmless the Foundation, trademark owner, and others from liability arising from distribution, alteration, or defects caused by the user.\n",
      "* The Project Gutenberg Literary Archive Foundation is a non-profit organization that relies on donations to maintain its mission of providing free electronic works.\n",
      "\n",
      "**Donations and Contact Information**\n",
      "\n",
      "* Donations are tax-deductible in the US and can be made online or by mail.\n",
      "* The Foundation's business office is located in Salt Lake City, UT, and contact information can be found on its website.\n",
      "* International donations are accepted, but tax treatment is not guaranteed.\n",
      "Passage 1: International donations are gratefully accepted, but we cannot make\n",
      "any statements concerning tax treatment of donations received from\n",
      "outside the United States. U.S. laws alone swamp our small staff.\n",
      "\n",
      "Please check the Project Gutenberg web pages for current donation\n",
      "methods and addresses. Donations are accepted in a number of other\n",
      "ways including checks, online payments and credit card donations. To\n",
      "donate, please visit: www.gutenberg.org/donate.\n",
      "\n",
      "Section 5. General Information About Project Gutenberg™ electronic works\n",
      "\n",
      "Professor Michael S. Hart was the originator of the Project\n",
      "Gutenberg™ concept of a library of electronic works that could be\n",
      "freely shared with anyone. For forty years, he produced and\n",
      "distributed Project Gutenberg™ eBooks with only a loose network of\n",
      "volunteer support.\n",
      "Passage 2: 1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the\n",
      "trademark owner, any agent or employee of the Foundation, anyone\n",
      "providing copies of Project Gutenberg™ electronic works in\n",
      "accordance with this agreement, and any volunteers associated with the\n",
      "production, promotion and distribution of Project Gutenberg™\n",
      "electronic works, harmless from all liability, costs and expenses,\n",
      "including legal fees, that arise directly or indirectly from any of\n",
      "the following which you do or cause to occur: (a) distribution of this\n",
      "or any Project Gutenberg™ work, (b) alteration, modification, or\n",
      "additions or deletions to any Project Gutenberg™ work, and (c) any\n",
      "Defect you cause.\n",
      "\n",
      "Section 2. Information about the Mission of Project Gutenberg™\n",
      "\n",
      "Project Gutenberg™ is synonymous with the free distribution of\n",
      "electronic works in formats readable by the widest variety of\n",
      "computers including obsolete, old, middle-aged and new computers. It\n",
      "exists because of the efforts of hundreds of volunteers and donations\n",
      "from people in all walks of life.\n",
      "\n",
      "Volunteers and financial support to provide volunteers with the\n",
      "assistance they need are critical to reaching Project Gutenberg™’s\n",
      "goals and ensuring that the Project Gutenberg™ collection will\n",
      "remain freely available for generations to come. In 2001, the Project\n",
      "Gutenberg Literary Archive Foundation was created to provide a secure\n",
      "and permanent future for Project Gutenberg™ and future\n",
      "generations. To learn more about the Project Gutenberg Literary\n",
      "Archive Foundation and how your efforts and donations can help, see\n",
      "Sections 3 and 4 and the Foundation information page at www.gutenberg.org.\n",
      "\n",
      "Section 3. Information about the Project Gutenberg Literary Archive Foundation\n",
      "\n",
      "The Project Gutenberg Literary Archive Foundation is a non-profit\n",
      "501(c)(3) educational corporation organized under the laws of the\n",
      "state of Mississippi and granted tax exempt status by the Internal\n",
      "Revenue Service. The Foundation’s EIN or federal tax identification\n",
      "number is 64-6221541. Contributions to the Project Gutenberg Literary\n",
      "Archive Foundation are tax deductible to the full extent permitted by\n",
      "U.S. federal laws and your state’s laws.\n",
      "\n",
      "The Foundation’s business office is located at 809 North 1500 West,\n",
      "Salt Lake City, UT 84116, (801) 596-1887. Email contact links and up\n",
      "to date contact information can be found at the Foundation’s website\n",
      "and official page at www.gutenberg.org/contact\n",
      "\n",
      "Section 4. Information about Donations to the Project Gutenberg\n",
      "Literary Archive Foundation\n",
      "\n",
      "Project Gutenberg™ depends upon and cannot survive without widespread\n",
      "public support and donations to carry out its mission of\n",
      "increasing the number of public domain and licensed works that can be\n",
      "freely distributed in machine-readable form accessible by the widest\n",
      "array of equipment including outdated equipment. Many small donations\n",
      "($1 to $5,000) are particularly important to maintaining tax exempt\n",
      "status with the IRS.\n",
      "\n",
      "The Foundation is committed to complying with the laws regulating\n",
      "charities and charitable donations in all 50 states of the United\n",
      "States. Compliance requirements are not uniform and it takes a\n",
      "considerable effort, much paperwork and many fees to meet and keep up\n",
      "with these requirements. We do not solicit donations in locations\n",
      "where we have not received written confirmation of compliance. To SEND\n",
      "DONATIONS or determine the status of compliance for any particular state\n",
      "visit www.gutenberg.org/donate.\n",
      "\n",
      "While we cannot and do not solicit contributions from states where we\n",
      "have not met the solicitation requirements, we know of no prohibition\n",
      "against accepting unsolicited donations from donors in such states who\n",
      "approach us with offers to donate.\n",
      "\n",
      "International donations are gratefully accepted, but we cannot make\n",
      "any statements concerning tax treatment of donations received from\n",
      "outside the United States. U.S. laws alone swamp our small staff.\n",
      "Passage 3: 1.E.9. If you wish to charge a fee or distribute a Project\n",
      "Gutenberg™ electronic work or group of works on different terms than\n",
      "are set forth in this agreement, you must obtain permission in writing\n",
      "from the Project Gutenberg Literary Archive Foundation, the manager of\n",
      "the Project Gutenberg™ trademark. Contact the Foundation as set\n",
      "forth in Section 3 below.\n",
      "\n",
      "1.F.\n",
      "\n",
      "1.F.1. Project Gutenberg volunteers and employees expend considerable\n",
      "effort to identify, do copyright research on, transcribe and proofread\n",
      "works not protected by U.S. copyright law in creating the Project\n",
      "Gutenberg™ collection. Despite these efforts, Project Gutenberg™\n",
      "electronic works, and the medium on which they may be stored, may\n",
      "contain “Defects,” such as, but not limited to, incomplete, inaccurate\n",
      "or corrupt data, transcription errors, a copyright or other\n",
      "intellectual property infringement, a defective or damaged disk or\n",
      "other medium, a computer virus, or computer codes that damage or\n",
      "cannot be read by your equipment.\n",
      "\n",
      "1.F.2. LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the “Right\n",
      "of Replacement or Refund” described in paragraph 1.F.3, the Project\n",
      "Gutenberg Literary Archive Foundation, the owner of the Project\n",
      "Gutenberg™ trademark, and any other party distributing a Project\n",
      "Gutenberg™ electronic work under this agreement, disclaim all\n",
      "liability to you for damages, costs and expenses, including legal\n",
      "fees. YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT\n",
      "LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE\n",
      "PROVIDED IN PARAGRAPH 1.F.3. YOU AGREE THAT THE FOUNDATION, THE\n",
      "TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE\n",
      "LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR\n",
      "INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH\n",
      "DAMAGE.\n",
      "\n",
      "1.F.3. LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a\n",
      "defect in this electronic work within 90 days of receiving it, you can\n",
      "receive a refund of the money (if any) you paid for it by sending a\n",
      "written explanation to the person you received the work from. If you\n",
      "received the work on a physical medium, you must return the medium\n",
      "with your written explanation. The person or entity that provided you\n",
      "with the defective work may elect to provide a replacement copy in\n",
      "lieu of a refund. If you received the work electronically, the person\n",
      "or entity providing it to you may choose to give you a second\n",
      "opportunity to receive the work electronically in lieu of a refund. If\n",
      "the second copy is also defective, you may demand a refund in writing\n",
      "without further opportunities to fix the problem.\n",
      "\n",
      "1.F.4. Except for the limited right of replacement or refund set forth\n",
      "in paragraph 1.F.3, this work is provided to you ‘AS-IS’, WITH NO\n",
      "OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT\n",
      "LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.\n",
      "\n",
      "1.F.5. Some states do not allow disclaimers of certain implied\n",
      "warranties or the exclusion or limitation of certain types of\n",
      "damages. If any disclaimer or limitation set forth in this agreement\n",
      "violates the law of the state applicable to this agreement, the\n",
      "agreement shall be interpreted to make the maximum disclaimer or\n",
      "limitation permitted by the applicable state law. The invalidity or\n",
      "unenforceability of any provision of this agreement shall not void the\n",
      "remaining provisions.\n"
     ]
    }
   ],
   "source": [
    "# Print the retrieved context\n",
    "print(\"Retrieved Context:\")\n",
    "print(result[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellUniqueIdByVincent": "11fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 root chunks:\n",
      "\n",
      "Root Chunk 1:\n",
      "ID: root_0_0\n",
      "Score: 0.6778\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/olande.txt\n",
      "Summary: Here is a concise summary of Chris Olande's professional profile:\n",
      "\n",
      "Chris Olande is a statistics and programming student at Kenyatta University with a strong background in data science, machine learnin...\n",
      "\n",
      "Root Chunk 2:\n",
      "ID: root_2_22\n",
      "Score: 0.3226\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt\n",
      "Summary: Here is a concise summary:\n",
      "\n",
      "Project Gutenberg is a digital library of free eBooks, founded by Professor Michael S. Hart, that can be accessed at www.gutenberg.org. Donations are accepted to support th...\n",
      "\n",
      "Root Chunk 3:\n",
      "ID: root_2_21\n",
      "Score: 0.3037\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt\n",
      "Summary: Here is a concise summary of the text:\n",
      "\n",
      "**Terms of Use for Project Gutenberg Electronic Works**\n",
      "\n",
      "* Permission is required to charge a fee or distribute works on different terms than specified.\n",
      "* Proje...\n"
     ]
    }
   ],
   "source": [
    "# Print information about the retrieved root chunks\n",
    "print(f\"Retrieved {len(result['root_chunks'])} root chunks:\")\n",
    "for i, chunk in enumerate(result['root_chunks']):\n",
    "    print(f\"\\nRoot Chunk {i+1}:\")\n",
    "    print(f\"ID: {chunk['id']}\")\n",
    "    print(f\"Score: {chunk['score']:.4f}\")\n",
    "    print(f\"Source: {chunk['metadata'].get('source', 'unknown')}\")\n",
    "    if 'summary' in chunk:\n",
    "        print(f\"Summary: {chunk['summary'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellUniqueIdByVincent": "d7285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 6 leaf chunks:\n",
      "\n",
      "Leaf Chunk 1:\n",
      "ID: leaf_0_0_1\n",
      "Score: 0.6304\n",
      "Parent ID: root_0_0\n",
      "Text: This dual commitment—to technology and to people—makes Chris a well-rounded and impactful contributo...\n",
      "\n",
      "Leaf Chunk 2:\n",
      "ID: leaf_0_0_0\n",
      "Score: 0.6118\n",
      "Parent ID: root_0_0\n",
      "Text: Chris Olande: A Professional Profile\n",
      "\n",
      "Chris Olande is a dynamic and intellectually curious student o...\n",
      "\n",
      "Leaf Chunk 3:\n",
      "ID: leaf_2_21_2\n",
      "Score: 0.3051\n",
      "Parent ID: root_2_21\n",
      "Text: International donations are gratefully accepted, but we cannot make\n",
      "any statements concerning tax tr...\n",
      "\n",
      "Leaf Chunk 4:\n",
      "ID: leaf_2_22_0\n",
      "Score: 0.2813\n",
      "Parent ID: root_2_22\n",
      "Text: Please check the Project Gutenberg web pages for current donation\n",
      "methods and addresses. Donations a...\n",
      "\n",
      "Leaf Chunk 5:\n",
      "ID: leaf_2_21_1\n",
      "Score: 0.2692\n",
      "Parent ID: root_2_21\n",
      "Text: 1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the\n",
      "trademark owner, any agent or...\n"
     ]
    }
   ],
   "source": [
    "# Print information about the retrieved leaf chunks\n",
    "print(f\"Retrieved {len(result['leaf_chunks'])} leaf chunks:\")\n",
    "for i, chunk in enumerate(result['leaf_chunks'][:5]):  # Show only the first 5 for brevity\n",
    "    print(f\"\\nLeaf Chunk {i+1}:\")\n",
    "    print(f\"ID: {chunk['id']}\")\n",
    "    print(f\"Score: {chunk['score']:.4f}\")\n",
    "    print(f\"Parent ID: {chunk['metadata'].get('parent_id', 'unknown')}\")\n",
    "    print(f\"Text: {chunk['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "fab26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:18,290 - __main__ - INFO - Retrieving relevant chunks for query: Who wrote the declaration of independence?\n",
      "2025-05-22 23:42:18,292 - retrieval - INFO - Retrieving chunks for query: Who wrote the declaration of independence?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who wrote the declaration of independence?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:19,012 - vector_store - INFO - Root query returned 3 results\n",
      "2025-05-22 23:42:19,255 - vector_store - INFO - Leaf query returned 9 results\n",
      "2025-05-22 23:42:19,257 - retrieval - INFO - Retrieved 3 root chunks and 9 leaf chunks\n",
      "2025-05-22 23:42:19,259 - __main__ - INFO - Generating response...\n",
      "2025-05-22 23:42:19,262 - llm_interface - INFO - Generating response for prompt: \n",
      "            Question: Who wrote the declaration o...\n",
      "2025-05-22 23:42:27,086 - llm_interface - INFO - Generated response: Who wrote the Declaration of Independence?\n",
      "\n",
      "Accord...\n",
      "2025-05-22 23:42:27,091 - __main__ - INFO - Query processed in 8.80 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Who wrote the Declaration of Independence?\n",
      "\n",
      "According to [Section 1] and [Section 2], the Declaration of Independence was written by **Thomas Jefferson**. \n",
      "\n",
      "The passage in [Section 1] specifically states: \"Author: Thomas Jefferson\".\n",
      "\n",
      "The passage in [Section 2] also mentions that the title of the eBook is \"The Declaration of Independence\" and the author is \"Thomas Jefferson\".\n",
      "\n",
      "Therefore, the answer to the question is that the Declaration of Independence was written by **Thomas Jefferson**.\n",
      "\n",
      "Query Time: 8.80 seconds\n"
     ]
    }
   ],
   "source": [
    "# Try another query about declaration of independence\n",
    "query = \"Who wrote the declaration of independence?\"\n",
    "result = ask_question(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellUniqueIdByVincent": "ab18a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:27,114 - __main__ - INFO - Retrieving relevant chunks for query: What are the unalienable rights mentioned in the declaration of independence?\n",
      "2025-05-22 23:42:27,116 - retrieval - INFO - Retrieving chunks for query: What are the unalienable rights mentioned in the declaration of independence?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the unalienable rights mentioned in the declaration of independence?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:27,870 - vector_store - INFO - Root query returned 3 results\n",
      "2025-05-22 23:42:28,101 - vector_store - INFO - Leaf query returned 9 results\n",
      "2025-05-22 23:42:28,102 - retrieval - INFO - Retrieved 3 root chunks and 9 leaf chunks\n",
      "2025-05-22 23:42:28,104 - __main__ - INFO - Generating response...\n",
      "2025-05-22 23:42:28,106 - llm_interface - INFO - Generating response for prompt: \n",
      "            Question: What are the unalienable ri...\n",
      "2025-05-22 23:42:42,506 - llm_interface - INFO - Generated response: **Unalienable Rights Mentioned in the Declaration ...\n",
      "2025-05-22 23:42:42,508 - __main__ - INFO - Query processed in 15.39 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "**Unalienable Rights Mentioned in the Declaration of Independence**\n",
      "\n",
      "The Declaration of Independence, written by Thomas Jefferson in 1776, mentions the following unalienable rights:\n",
      "\n",
      "* **Life**: The right to life is considered a fundamental and inalienable right, essential to human existence.\n",
      "* **Liberty**: The right to liberty refers to the freedom to make choices and live one's life as one sees fit, without undue interference from others.\n",
      "* **Pursuit of Happiness**: The right to pursue happiness is a fundamental aspect of human nature, allowing individuals to strive for their own well-being and fulfillment.\n",
      "\n",
      "These rights are mentioned in the following passage:\n",
      "\n",
      "\"We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty, and the pursuit of Happiness.\"\n",
      "\n",
      "These rights are considered unalienable, meaning they cannot be taken away or denied by any government or authority. They are fundamental to the human experience and are essential to the creation of a just and equitable society.\n",
      "\n",
      "Query Time: 15.39 seconds\n"
     ]
    }
   ],
   "source": [
    "# Try a more specific query\n",
    "query = \"What are the unalienable rights mentioned in the declaration of independence?\"\n",
    "result = ask_question(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellUniqueIdByVincent": "0a5f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:42,529 - config - INFO - All required configuration variables are present.\n",
      "2025-05-22 23:42:42,580 - document_processor - INFO - Initialized HierarchicalDocumentProcessor with knowledge base path: /home/olande/Desktop/Rag_Techniques/HRAG/books\n",
      "2025-05-22 23:42:42,581 - document_processor - INFO - Leaf chunk size: 1000, Root chunk size: 4000\n",
      "2025-05-22 23:42:42,591 - embedding - INFO - Initialized EmbeddingGenerator with model: models/text-embedding-004\n",
      "2025-05-22 23:42:42,593 - embedding - INFO - Embedding dimensions: 768\n",
      "2025-05-22 23:42:43,006 - vector_store - INFO - Pinecone index already exists: hrag-gemini-768\n",
      "2025-05-22 23:42:43,308 - embedding - INFO - Initialized EmbeddingGenerator with model: models/text-embedding-004\n",
      "2025-05-22 23:42:43,309 - embedding - INFO - Embedding dimensions: 768\n",
      "2025-05-22 23:42:43,851 - vector_store - INFO - Pinecone index already exists: hrag-gemini-768\n",
      "2025-05-22 23:42:45,177 - retrieval - INFO - Initialized HierarchicalRetriever with top_k_root=2, top_k_leaf=3\n",
      "2025-05-22 23:42:45,179 - retrieval - INFO - Initialized HierarchicalRetrievalPipeline with top_k_root=2, top_k_leaf=3\n",
      "2025-05-22 23:42:45,232 - llm_interface - INFO - Initialized LLMInterface with model: meta-llama/llama-3.1-8b-instruct\n",
      "2025-05-22 23:42:45,233 - __main__ - INFO - Initialized HierarchicalRAG with top_k_root=2, top_k_leaf=3\n",
      "2025-05-22 23:42:45,235 - __main__ - INFO - Retrieving relevant chunks for query: What grievances were listed in the declaration of independence?\n",
      "2025-05-22 23:42:45,239 - retrieval - INFO - Retrieving chunks for query: What grievances were listed in the declaration of independence?\n",
      "2025-05-22 23:42:47,628 - vector_store - INFO - Root query returned 2 results\n",
      "2025-05-22 23:42:47,862 - vector_store - INFO - Leaf query returned 6 results\n",
      "2025-05-22 23:42:47,864 - retrieval - INFO - Retrieved 2 root chunks and 6 leaf chunks\n",
      "2025-05-22 23:42:47,867 - __main__ - INFO - Generating response...\n",
      "2025-05-22 23:42:47,868 - llm_interface - INFO - Generating response for prompt: \n",
      "            Question: What grievances were listed...\n",
      "2025-05-22 23:42:54,131 - llm_interface - INFO - Generated response: **Grievances listed in the Declaration of Independ...\n",
      "2025-05-22 23:42:54,135 - __main__ - INFO - Query processed in 8.90 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What grievances were listed in the declaration of independence?\n",
      "\n",
      "Answer:\n",
      "**Grievances listed in the Declaration of Independence**\n",
      "\n",
      "The Declaration of Independence, written by Thomas Jefferson in 1776, lists 27 grievances against King George III. These grievances can be summarized as follows:\n",
      "\n",
      "**Passage 1**\n",
      "\n",
      "* Refused to pass laws for the public good\n",
      "* Imposed taxes without consent\n",
      "* Abolished trial by jury\n",
      "* Quartered large numbers of soldiers in the colonies\n",
      "* Interfered with trade and commerce\n",
      "* Transported colonists to be tried for crimes in Britain\n",
      "\n",
      "**Passage 2**\n",
      "\n",
      "* Quartered large bodies of armed troops among the colonists\n",
      "* Protected them from punishment for murders committed on the inhabitants of the colonies\n",
      "* Cut off trade with all parts of the world\n",
      "* Imposed taxes without consent\n",
      "* Denied the benefits of trial by jury\n",
      "* Transported colonists to be tried for pretended offenses\n",
      "* Abolished the free system of English laws in a neighboring province\n",
      "* Established an arbitrary government and enlarged its boundaries\n",
      "* Took away the charters and most valuable laws of the colonies\n",
      "* Suspended the legislatures and declared themselves invested with power to legislate for the colonies in all cases\n",
      "\n",
      "**Passage 3**\n",
      "\n",
      "* Abdicated government by declaring the colonies out of his protection and waging war against them\n",
      "* Plundered the seas, ravaged the coastlines, and destroyed towns and lives of the colonists\n",
      "* Transported large armies of foreign mercenaries to complete the works of death and tyranny\n",
      "* Constrained fellow citizens taken captive on the high seas to bear arms against their country or fall by their hands\n",
      "\n",
      "These grievances were listed in the Declaration of Independence as evidence of the British monarchy's abuse of power and its intention to establish absolute tyranny over the colonies.\n",
      "\n",
      "Query Time: 8.90 seconds\n",
      "\n",
      "Retrieved 2 root chunks and 6 leaf chunks\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance with different retrieval parameters\n",
    "custom_rag = HierarchicalRAG(top_k_root=2, top_k_leaf=3)\n",
    "\n",
    "# Try a query with the custom parameters\n",
    "query = \"What grievances were listed in the declaration of independence?\"\n",
    "custom_result = custom_rag.query(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"\\nAnswer:\")\n",
    "print(custom_result[\"answer\"])\n",
    "print(f\"\\nQuery Time: {custom_result['query_time']:.2f} seconds\")\n",
    "print(f\"\\nRetrieved {len(custom_result['root_chunks'])} root chunks and {len(custom_result['leaf_chunks'])} leaf chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "4fe14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:54,160 - __main__ - INFO - Retrieving relevant chunks for query: How did Romeo die?\n",
      "2025-05-22 23:42:54,163 - retrieval - INFO - Retrieving chunks for query: How did Romeo die?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How did Romeo die?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 23:42:54,854 - vector_store - INFO - Root query returned 3 results\n",
      "2025-05-22 23:42:55,090 - vector_store - INFO - Leaf query returned 9 results\n",
      "2025-05-22 23:42:55,092 - retrieval - INFO - Retrieved 3 root chunks and 9 leaf chunks\n",
      "2025-05-22 23:42:55,093 - __main__ - INFO - Generating response...\n",
      "2025-05-22 23:42:55,094 - llm_interface - INFO - Generating response for prompt: \n",
      "            Question: How did Romeo die?\n",
      "\n",
      "       ...\n",
      "2025-05-22 23:43:03,650 - llm_interface - INFO - Generated response: **Romeo's Death**\n",
      "\n",
      "Romeo's death occurs in the Cap...\n",
      "2025-05-22 23:43:03,654 - __main__ - INFO - Query processed in 9.49 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "**Romeo's Death**\n",
      "\n",
      "Romeo's death occurs in the Capulet family tomb, where he has gone to be with Juliet's body. He has obtained a poison from an apothecary in Mantua and intends to use it to end his life. \n",
      "\n",
      "Upon entering the tomb, Romeo finds Paris's body and is grief-stricken. He then lays Paris in the tomb and begins to lament his own fate, comparing it to a \"lightning before death\" and a \"lantern, slaught'rd youth.\" \n",
      "\n",
      "Romeo then decides to die alongside Juliet, whom he believes is already dead. He takes the poison and drinks it, saying \"O true apothecary! / Thy drugs are quick. / Thus with a kiss I die\" (Passage 3). \n",
      "\n",
      "Romeo's body is found by Friar Lawrence, who is shocked to see him dead. Friar Lawrence enters the tomb and finds Juliet, who has also died from a dagger wound. \n",
      "\n",
      "The Prince and the Watch enter the scene, and they discover the bodies of Romeo, Paris, and Juliet. The Prince orders an investigation into the murder, and the scene ends with the Prince calling for patience and forbearance while the truth is uncovered. \n",
      "\n",
      "**Key Passages**\n",
      "\n",
      "* Passage 3: \"Romeo! O, pale! Who else? What, Paris too? / And steep'd in blood? Ah what an unkind hour / Is guilty of this lamentable chance?\" (FRIAR LAWRENCE)\n",
      "* Passage 3: \"Thou detestable maw, thou womb of death, / Gorg'd with the dearest morsel of the earth, / Thus I enforce thy rotten jaws to open, / And in despite, I'll cram thee with more food.\" (Romeo)\n",
      "* Passage 3: \"Romeo! O, pale! Who else? What, Paris too? / And steep'd in blood? Ah what an unkind hour / Is guilty of this lamentable chance?\" (FRIAR LAWRENCE)\n",
      "* Passage 3: \"O, here / Will I set up my everlasting rest; / And shake the yoke of inauspicious stars / From this world-wearied flesh. Eyes, look your last. / Arms, take your last embrace! And, lips, O you / The doors of breath, seal with a righteous kiss / A dateless bargain to engrossing death.\" (Romeo)\n",
      "* Passage 3: \"Thou desperate pilot, now at once run on / The dashing rocks thy sea-sick weary bark. / Here's to my love! [Drinks.] O true apothecary! / Thy drugs are quick. Thus with a kiss I die.\" (Romeo)\n",
      "\n",
      "Query Time: 9.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ask questions about romeo and juliet\n",
    "query = \"How did Romeo die?\"\n",
    "result = ask_question(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellUniqueIdByVincent": "dbd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 root chunks:\n",
      "\n",
      "Root Chunk 1:\n",
      "ID: root_2_17\n",
      "Score: 0.6651\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt\n",
      "Summary: Here is a concise summary of the scene:\n",
      "\n",
      "Romeo, desperate to be with Juliet, decides to buy a poison from an apothecary in Mantua. He pays the apothecary with 40 ducats and obtains the poison, which he intends to use to end his life. Meanwhile, Friar Lawrence is unaware of Romeo's plan and is trying...\n",
      "\n",
      "Root Chunk 2:\n",
      "ID: root_2_18\n",
      "Score: 0.6616\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt\n",
      "Summary: Here is a concise summary of the scene:\n",
      "\n",
      "Romeo and Paris fight and Paris is killed. Romeo, grief-stricken, enters the Capulet family tomb where Juliet lies, and he drinks a poison that kills him. Juliet wakes up and finds Romeo dead, and in a fit of grief, she kills herself with his dagger. The Prin...\n",
      "\n",
      "Root Chunk 3:\n",
      "ID: root_2_10\n",
      "Score: 0.6598\n",
      "Source: /home/olande/Desktop/Rag_Techniques/HRAG/books/romeo_and_juliet.txt\n",
      "Summary: Here is a concise summary of the scene:\n",
      "\n",
      "Mercutio, a friend of Romeo, is killed in a fight with Tybalt, a member of the Capulet family. Romeo, who had tried to stop the fight, is accused of killing Tybalt and is banished from Verona by Prince Escalus. Meanwhile, Juliet is unaware of the events that ...\n"
     ]
    }
   ],
   "source": [
    "# Print information about the retrieved root chunks\n",
    "print(f\"Retrieved {len(result['root_chunks'])} root chunks:\")\n",
    "for i, chunk in enumerate(result['root_chunks']):\n",
    "    print(f\"\\nRoot Chunk {i+1}:\")\n",
    "    print(f\"ID: {chunk['id']}\")\n",
    "    print(f\"Score: {chunk['score']:.4f}\")\n",
    "    print(f\"Source: {chunk['metadata'].get('source', 'unknown')}\")\n",
    "    if 'summary' in chunk:\n",
    "        print(f\"Summary: {chunk['summary'][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellUniqueIdByVincent": "f3b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 9 leaf chunks:\n",
      "\n",
      "Leaf Chunk 1:\n",
      "ID: leaf_2_10_1\n",
      "Score: 0.6453\n",
      "Parent ID: root_2_10\n",
      "Text: PRINCE.\n",
      "Romeo slew him, he slew Mercutio.\n",
      "Who now the price of his dear blood doth owe?\n",
      "\n",
      "MONTAGUE.\n",
      "Not Romeo, Prince, he was Mercutio’s friend;\n",
      "His fault concludes but what the law should end,\n",
      "The lif...\n",
      "\n",
      "Leaf Chunk 2:\n",
      "ID: leaf_2_17_2\n",
      "Score: 0.6405\n",
      "Parent ID: root_2_17\n",
      "Text: PARIS.\n",
      "I do defy thy conjuration,\n",
      "And apprehend thee for a felon here.\n",
      "\n",
      "ROMEO.\n",
      "Wilt thou provoke me? Then have at thee, boy!\n",
      "\n",
      " [_They fight._]\n",
      "\n",
      "PAGE.\n",
      "O lord, they fight! I will go call the watch.\n",
      "\n",
      " [_...\n",
      "\n",
      "Leaf Chunk 3:\n",
      "ID: leaf_2_18_1\n",
      "Score: 0.6349\n",
      "Parent ID: root_2_18\n",
      "Text: [_Enters the monument._]\n",
      "\n",
      "Romeo! O, pale! Who else? What, Paris too?\n",
      "And steep’d in blood? Ah what an unkind hour\n",
      "Is guilty of this lamentable chance?\n",
      "The lady stirs.\n",
      "\n",
      " [_Juliet wakes and stirs._]\n",
      "\n",
      "JU...\n",
      "\n",
      "Leaf Chunk 4:\n",
      "ID: leaf_2_10_0\n",
      "Score: 0.6282\n",
      "Parent ID: root_2_10\n",
      "Text: ROMEO.\n",
      "I thought all for the best.\n",
      "\n",
      "MERCUTIO.\n",
      "Help me into some house, Benvolio,\n",
      "Or I shall faint. A plague o’ both your houses.\n",
      "They have made worms’ meat of me.\n",
      "I have it, and soundly too. Your hous...\n",
      "\n",
      "Leaf Chunk 5:\n",
      "ID: leaf_2_18_0\n",
      "Score: 0.6276\n",
      "Parent ID: root_2_18\n",
      "Text: PARIS.\n",
      "I do defy thy conjuration,\n",
      "And apprehend thee for a felon here.\n",
      "\n",
      "ROMEO.\n",
      "Wilt thou provoke me? Then have at thee, boy!\n",
      "\n",
      " [_They fight._]\n",
      "\n",
      "PAGE.\n",
      "O lord, they fight! I will go call the watch.\n",
      "\n",
      " [_...\n"
     ]
    }
   ],
   "source": [
    "# Print information about the retrieved leaf chunks\n",
    "print(f\"Retrieved {len(result['leaf_chunks'])} leaf chunks:\")\n",
    "for i, chunk in enumerate(result['leaf_chunks'][:5]):  # Show only the first 5 for brevity\n",
    "    print(f\"\\nLeaf Chunk {i+1}:\")\n",
    "    print(f\"ID: {chunk['id']}\")\n",
    "    print(f\"Score: {chunk['score']:.4f}\")\n",
    "    print(f\"Parent ID: {chunk['metadata'].get('parent_id', 'unknown')}\")\n",
    "    print(f\"Text: {chunk['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "vincent": {
   "sessionId": "93fea94e37784a8b1ac89b00_2025-05-22T10-26-47-366Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
