{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6155cf",
   "metadata": {
    "cellUniqueIdByVincent": "9eee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import asyncio\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Any, List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from asyncio import sleep\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type # To implement exponential backoff\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Embeddings and LLM imports\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Vector store imports \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Document Loader Imports\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader, \n",
    "    UnstructuredMarkdownLoader,\n",
    "    JSONLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    "    PyPDFLoader\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Prompt and template imports\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "# Langchain  runnables and pipeline imports\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "# Callbacks and logging imports\n",
    "from langchain.callbacks.base import AsyncCallbackHandler\n",
    "from langchain.schema import LLMResult\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20293f49",
   "metadata": {
    "cellUniqueIdByVincent": "2ee0a"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SelfRAGResponse:\n",
    "    \"\"\"Complete self rag with reflection\"\"\"\n",
    "    answer: str\n",
    "    retrieved_docs: List[Document]\n",
    "    reflection_score: float\n",
    "    needs_retrieval: bool\n",
    "    citations: List[str]\n",
    "    retrieval_decision_reasoning: str\n",
    "\n",
    "class RateLimitCallbackHandler(AsyncCallbackHandler):\n",
    "    \"\"\"Callback handler to manage API rate limiting with semaphores\"\"\"\n",
    "    \n",
    "    def __init__(self, semaphore: asyncio.Semaphore):\n",
    "        self.semaphore = semaphore\n",
    "        \n",
    "    async def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> None:\n",
    "        await self.semaphore.acquire()\n",
    "        \n",
    "    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n",
    "        self.semaphore.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e1ab11",
   "metadata": {
    "cellUniqueIdByVincent": "948ec"
   },
   "outputs": [],
   "source": [
    "class RateLimitedCohereEmbeddings:\n",
    "    \"\"\"Wrapper for Cohere embeddings with rate limiting and retry logic\"\"\"\n",
    "    def __init__(self, model: str, cohere_api_key: str, max_concurrent: int = 2, delay_between_calls: float = 0.5, batch_size: int = 30):\n",
    "        self.base_embeddings = CohereEmbeddings(\n",
    "            model = model,\n",
    "            cohere_api_key = cohere_api_key\n",
    "        )\n",
    "\n",
    "        self.semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        self.delay_between_calls = delay_between_calls\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(5),\n",
    "        wait=wait_exponential(multiplier=1, min=1, max=60),\n",
    "        retry=retry_if_exception_type((httpx.HTTPStatusError, Exception))\n",
    "    )\n",
    "\n",
    "    async def _embed_with_retry(self, texts:List[str])-> List[List[float]]:\n",
    "        \"\"\"Embed texts with retry logic\"\"\"\n",
    "        async with self.semaphore:\n",
    "            # Ensure minimum delay between calls\n",
    "            current_time = asyncio.get_event_loop().time()\n",
    "            time_since_last_call = current_time - self.last_call_time\n",
    "            if time_since_last_call < self.delay_between_calls:\n",
    "                await sleep(self.delay_between_calls - time_since_last_call)\n",
    "            \n",
    "            try:\n",
    "                logger.debug(f\"Embedding batch of {len(texts)} texts\")\n",
    "                result = await self.base_embeddings.aembed_documents(texts)\n",
    "                self.last_call_time = asyncio.get_event_loop().time()\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e) or \"Too Many Requests\" in str(e):\n",
    "                    logger.warning(f\"Rate limit hit, retrying after delay...\")\n",
    "                    await sleep(2)  # Additional delay for rate limits\n",
    "                    raise\n",
    "                else:\n",
    "                    logger.error(f\"Embedding error: {e}\")\n",
    "                    raise\n",
    "    \n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed documents with batching and rate limiting\"\"\"\n",
    "        if not texts:\n",
    "            return []\n",
    "        \n",
    "        # Use configurable batch size\n",
    "        all_embeddings = []\n",
    "        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        logger.info(f\"Processing {len(texts)} texts in {total_batches} batches of {self.batch_size}\")\n",
    "        \n",
    "        for i in range(0, len(texts), self.batch_size):\n",
    "            batch_num = (i // self.batch_size) + 1\n",
    "            batch = texts[i:i + self.batch_size]\n",
    "            \n",
    "            logger.info(f\"Processing batch {batch_num}/{total_batches} ({len(batch)} texts)\")\n",
    "            \n",
    "            batch_embeddings = await self._embed_with_retry(batch)\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "            \n",
    "            # Delay between batches (except for the last one)\n",
    "            if i + self.batch_size < len(texts):\n",
    "                await sleep(self.delay_between_calls)\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed a single query\"\"\"\n",
    "        async with self.semaphore:\n",
    "            current_time = asyncio.get_event_loop().time()\n",
    "            time_since_last_call = current_time - self.last_call_time\n",
    "            if time_since_last_call < self.delay_between_calls:\n",
    "                await sleep(self.delay_between_calls - time_since_last_call)\n",
    "            \n",
    "            result = await self.base_embeddings.aembed_query(text)\n",
    "            self.last_call_time = asyncio.get_event_loop().time()\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e8cb6",
   "metadata": {
    "cellUniqueIdByVincent": "52d9a"
   },
   "outputs": [],
   "source": [
    "class DocumentLoader:\n",
    "    def __init__(self):\n",
    "        self.loaders = {\n",
    "            \".txt\": TextLoader,\n",
    "            \".md\": UnstructuredMarkdownLoader,\n",
    "            \".json\": self._create_json_loader,\n",
    "            \".pdf\": PyPDFLoader,\n",
    "            \".html\": UnstructuredHTMLLoader,\n",
    "            \".py\": TextLoader,\n",
    "            \".js\": TextLoader,\n",
    "            \".css\": TextLoader\n",
    "        }\n",
    "\n",
    "    def _create_json_loader(self, file_path: str):\n",
    "        \"\"\"Create JSON loader with custom jq_schema\"\"\"\n",
    "        return JSONLoader(\n",
    "            file_path=file_path,\n",
    "            jq_schema='.[]',\n",
    "            text_content=False\n",
    "        )\n",
    "\n",
    "    async def load_documents(self, kb_folder: str) -> List[Document]:\n",
    "        \"\"\"Load all documents from the knowledge base folder\"\"\"\n",
    "        documents = []\n",
    "        kb_path = Path(kb_folder)\n",
    "\n",
    "        if not kb_path.exists():\n",
    "            raise FileNotFoundError(f\"Knowledge base folder not found: {kb_path}\")\n",
    "\n",
    "        for file_path in kb_path.glob(\"**/*\"):\n",
    "            if file_path.is_file() and file_path.suffix.lower() in self.loaders:\n",
    "                try:\n",
    "                    loader_class = self.loaders[file_path.suffix.lower()]\n",
    "\n",
    "                    if file_path.suffix.lower() == \".json\":\n",
    "                        loader = loader_class(str(file_path))\n",
    "                    else:\n",
    "                        loader = loader_class(str(file_path))\n",
    "\n",
    "                    docs = loader.load()\n",
    "\n",
    "                    # Add metadata\n",
    "                    for doc in docs:\n",
    "                        doc.metadata.update({\n",
    "                            'file_path': str(file_path),\n",
    "                            'file_type': file_path.suffix,\n",
    "                            'file_name': file_path.name\n",
    "                        })\n",
    "\n",
    "                    documents.extend(docs)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"There was an error loading the knowledge base: {str(e)}\")\n",
    "                    # Fallback to TextLoader for unknown formats\n",
    "                    try:\n",
    "                        loader = TextLoader(str(file_path))\n",
    "                        docs = loader.load()\n",
    "                        # Add metadata\n",
    "                        for doc in docs:\n",
    "                            doc.metadata.update({\n",
    "                                'file_path': str(file_path),\n",
    "                                'file_type': file_path.suffix,\n",
    "                                'file_name': file_path.name\n",
    "                            })\n",
    "\n",
    "                        documents.extend(docs)\n",
    "\n",
    "                    except Exception as fallback_error:\n",
    "                        logger.error(f\"Failed to load {file_path} with fallback: {fallback_error}\")\n",
    "        \n",
    "        logger.info(f\"Loaded {len(documents)} documents from {kb_folder}\")\n",
    "        return documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "vincent": {
   "sessionId": "3f2153659d5b596a4189cf1d_2025-05-30T15-07-59-793Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
