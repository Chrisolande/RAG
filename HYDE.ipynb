{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0ca898",
   "metadata": {
    "cellUniqueIdByVincent": "6c35d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def get_api_key(key_name=\"OPENROUTER_API_KEY\"):\n",
    "    \"\"\"\n",
    "    Get API key from environment variables\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(key_name)\n",
    "    if not api_key:\n",
    "        raise ValueError(f\"Invalid API key: {key_name} not found in environment variables\")\n",
    "    return api_key\n",
    "\n",
    "def initialize_llm(model_name=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "                  temperature=0.4,\n",
    "                  use_streaming=True):\n",
    "    \"\"\"\n",
    "    Initialize LLM\n",
    "    \"\"\"\n",
    "    api_key = get_api_key()\n",
    "    callbacks = [StreamingStdOutCallbackHandler()]\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "        streaming=use_streaming,\n",
    "        callbacks=callbacks,\n",
    "        openai_api_key=api_key,\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellUniqueIdByVincent": "3c558"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Connect to Pinecone\n",
    "def connect_to_pinecone(api_key = os.getenv(\"PINECONE_API_KEY\")):\n",
    "    \"\"\"\n",
    "    Connect to Pinecone with your API key\n",
    "    \"\"\"\n",
    "    # Initialize the Pinecone client with the new API\n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    print(\"Connected to Pinecone\")\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "582d8"
   },
   "outputs": [],
   "source": [
    "# Create Pinecone index with 768 dimensions to match existing index\n",
    "def create_pinecone_index(dimension=768, index_name=\"hyde-index\", metric=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Create or connect to a Pinecone index\n",
    "    \"\"\"\n",
    "    pc = connect_to_pinecone()\n",
    "    \n",
    "    # Check if index already exists\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        # Create index with the new API - using gcp-starter which is free tier compatible\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric=metric\n",
    "            \n",
    "        )\n",
    "        print(f\"Created new index: {index_name}\")\n",
    "    else:\n",
    "        print(f\"Using existing index: {index_name}\")\n",
    "    \n",
    "    # Return the index\n",
    "    return pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellUniqueIdByVincent": "cc5c5"
   },
   "outputs": [],
   "source": [
    "# Get embeddings that match the 768 dimension requirement\n",
    "def get_embedding(text, model_name=\"models/embedding-001\"):\n",
    "    \"\"\"\n",
    "    Get 768-dimensional embeddings using Google's text-embedding-gecko model\n",
    "\n",
    "    \"\"\"\n",
    "    result = genai.embed_content(\n",
    "        model=model_name,\n",
    "        content=text,\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "    )\n",
    "    \n",
    "    return result[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellUniqueIdByVincent": "7fab6"
   },
   "outputs": [],
   "source": [
    "def insert_documents_to_pinecone(index, documents, namespace=\"\"):\n",
    "    \"\"\"\n",
    "    Insert documents with their embeddings to Pinecone\n",
    "    \"\"\"\n",
    "    # Generate embeddings that match the dimension of the index (768)\n",
    "    embeddings = []\n",
    "    for doc in documents:\n",
    "        embedding = get_embedding(doc)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    # Prepare data for upsert\n",
    "    vectors = []\n",
    "    for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "        vectors.append({\n",
    "            \"id\": f\"doc_{i}\",\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\"text\": doc}\n",
    "        })\n",
    "    \n",
    "    # Upsert vectors in batches\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        index.upsert(vectors=batch, namespace=namespace)\n",
    "    \n",
    "    print(f\"Inserted {len(vectors)} documents into Pinecone\")\n",
    "    return len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellUniqueIdByVincent": "af1a7"
   },
   "outputs": [],
   "source": [
    "# Search in Pinecone\n",
    "def search_pinecone(index, query, top_k=2):\n",
    "    \"\"\"\n",
    "    Search for similar documents in Pinecone\n",
    "    \"\"\"\n",
    "    # Get embedding for the query\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # Query the index\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    search_results = []\n",
    "    for match in results[\"matches\"]:\n",
    "        search_results.append((match[\"metadata\"][\"text\"], match[\"score\"]))\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "fd8ad"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "vincent": {
   "sessionId": "ddd5eacecd988c1d0d6edec0_2025-05-19T14-52-59-225Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
